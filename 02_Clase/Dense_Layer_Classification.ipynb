{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Unzip folder"
      ],
      "metadata": {
        "id": "mHsZWDDs4LVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'images.zip' -d images/"
      ],
      "metadata": {
        "id": "sFL5X-V14QJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "lyyzBAoy4iO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "t9YnATN_4kpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Data"
      ],
      "metadata": {
        "id": "xiI7gCzz5iQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear las listas archivos de audio y su etiqueta correspondiente\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def getExamples(datafolder):\n",
        "  X_Image = []\n",
        "  Y_Classification = []\n",
        "\n",
        "  # Clasificaciones de clases\n",
        "  image_classes = [os.path.basename(x) for x in glob.glob(datafolder + '*')]\n",
        "\n",
        "  for i, image_class in enumerate(image_classes):\n",
        "    for file in glob.glob(os.path.join(datafolder, image_class) + '/*.jpg'):\n",
        "      X_Image.append(file)\n",
        "      Y_Classification.append(np.array(to_categorical(i, num_classes=len(image_classes)),dtype=np.float32))\n",
        "  return np.asarray(X_Image), np.asarray(Y_Classification)"
      ],
      "metadata": {
        "id": "eYBuzKh05qUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datafolder= '/content/images/'\n",
        "X_Image, Y_Class = getExamples(datafolder)\n",
        "print(len(X_Image), len(Y_Class))"
      ],
      "metadata": {
        "id": "qnprQTow6MdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_Image[147])\n",
        "print(Y_Class[147])"
      ],
      "metadata": {
        "id": "tnKKo01YsK1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Image, X_Image_test, Y_Class, Y_Class_test = train_test_split(X_Image, Y_Class, test_size=0.25)\n",
        "print(len(X_Image))\n",
        "print(len(Y_Class))"
      ],
      "metadata": {
        "id": "EPqjmcg76nek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert file paths to tensors"
      ],
      "metadata": {
        "id": "cHWYPny8heVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadExample(example):\n",
        "  # Cargar la imagen\n",
        "  img = tf.io.read_file(example)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.rgb_to_grayscale(img);\n",
        "  img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "  #img = img/255.0\n",
        "  img = tf.reshape(img, [-1]);\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "q8TBb4rBhjcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementar el generador de Datos\n",
        "\n",
        "class MySequence(tf.keras.utils.Sequence):\n",
        "\n",
        "  def __init__(self, x_image, y_class, batch_size):\n",
        "    self.x_image = x_image\n",
        "    self.y_class = y_class\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_image)//self.batch_size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    batch_y = self.y_class[idx * self.batch_size : (idx+1)*self.batch_size]\n",
        "    batch_x = np.zeros((self.batch_size, s.shape[0]), dtype=np.float32)\n",
        "    for i in range(0, self.batch_size):\n",
        "      batch_x[i] = loadExample(self.x_image[idx * self.batch_size + i])\n",
        "    return batch_x, batch_y"
      ],
      "metadata": {
        "id": "WroQouxJ6-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la forma de los datos de entrada y la salida esperada\n",
        "\n",
        "mS=MySequence(X_Image, Y_Class, 32)\n",
        "my_data=iter(mS)\n",
        "bx, by = next(my_data)\n",
        "print(bx.shape, by.shape)"
      ],
      "metadata": {
        "id": "jkq5db_q7bw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bx.dtype"
      ],
      "metadata": {
        "id": "WYnaFXOXw3Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a Dense Layer"
      ],
      "metadata": {
        "id": "9qtL_ZmSj4sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense_Relu(tf.Module):\n",
        "  #def __init__(self):\n",
        "  def __init__(self, n_inputs, n_outputs, name=None):\n",
        "    super().__init__(name=name)\n",
        "    initial_w = tf.zeros(shape=[n_inputs, n_outputs], dtype=tf.float32)\n",
        "    initial_b = tf.zeros(shape=[n_outputs], dtype=tf.float32)\n",
        "    self.w = tf.Variable(initial_w)\n",
        "    self.b = tf.Variable(initial_b)\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, w):\n",
        "    return tf.nn.relu(tf.matmul(w,self.w)  + self.b)\n",
        "\n",
        "class Dense_SoftMax(tf.Module):\n",
        "  #def __init__(self):\n",
        "  def __init__(self, n_inputs, n_outputs, name=None):\n",
        "    super().__init__(name=name)\n",
        "    initial_w = tf.zeros(shape=[n_inputs, n_outputs], dtype=tf.float32)\n",
        "    initial_b = tf.zeros(shape=[n_outputs], dtype=tf.float32)\n",
        "    self.w = tf.Variable(initial_w)\n",
        "    self.b = tf.Variable(initial_b)\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, w):\n",
        "    return tf.nn.softmax(tf.matmul(w,self.w) + self.b)"
      ],
      "metadata": {
        "id": "1GS4V1BBj6tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FC_Model(tf.Module):\n",
        "  def __init__(self, name=None):\n",
        "    super().__init__(name=name)\n",
        "    self.dense_1 = Dense_Relu(n_inputs=307200, n_outputs=10)\n",
        "    self.dense_2 = Dense_SoftMax(n_inputs=10, n_outputs=2)\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[None,307200], dtype=tf.float32)])\n",
        "  def __call__(self, x):\n",
        "    x = self.dense_1(x)\n",
        "    return self.dense_2(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "SFfqnFXWloQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Watch Graph"
      ],
      "metadata": {
        "id": "cEUhfGpJkC5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "from datetime import datetime\n",
        "# Set up logging.\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = \"logs/funcs/%s\" % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "# Create a new model to get a fresh trace\n",
        "# Otherwise the summary will not see the graph.\n",
        "new_model = FC_Model()\n",
        "\n",
        "# Bracket the function call with\n",
        "# tf.summary.trace_on() and tf.summary.trace_export().\n",
        "tf.summary.trace_on(graph=True)\n",
        "tf.profiler.experimental.start(logdir)\n",
        "# Call only one tf.function when tracing.\n",
        "z = print(new_model( tf.random.uniform(shape=[1,307200], minval=-1.0, maxval=1.0)))\n",
        "with writer.as_default():\n",
        "  tf.summary.trace_export(\n",
        "      name=\"my_func_trace\",\n",
        "      step=0,\n",
        "      profiler_outdir=logdir)\n",
        "%tensorboard --logdir logs/funcs"
      ],
      "metadata": {
        "id": "rHFiR5mKkEYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = FC_Model()"
      ],
      "metadata": {
        "id": "6cITRgbK-T1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use Predefied Loss Function Categorical Cross Entropy"
      ],
      "metadata": {
        "id": "xDJg2ftwzu56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy();"
      ],
      "metadata": {
        "id": "irKjQ1v3uGed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "iA9fOXaU2lUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  my_data=iter(mS)\n",
        "  for x_batch, y_batch in my_data:\n",
        "    with tf.GradientTape() as tape:\n",
        "      batch_loss = loss(new_model(x_batch), y_batch)\n",
        "\n",
        "    # Update parameters with respect to the gradient calculations\n",
        "    grads = tape.gradient(batch_loss, new_model.variables)\n",
        "    for g,v in zip(grads, new_model.variables):\n",
        "        v.assign_sub(0.001*g)\n",
        "  # Keep track of model loss per epoch\n",
        "  loss_val = loss(new_model(x_batch), y_batch)\n",
        "  print(f\"Epoch {epoch} Loss  is {loss_val}\",)"
      ],
      "metadata": {
        "id": "zxvkm2yX2mnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotExample(example):\n",
        "  # Cargar la imagen\n",
        "  img = tf.io.read_file(example)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  plt.imshow(img)"
      ],
      "metadata": {
        "id": "1aPbwuTQfNNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=10\n",
        "print(Y_Class_test[i])\n",
        "print(X_Image_test[i])\n",
        "pred = new_model([loadExample(X_Image_test[i])])\n",
        "print(pred)\n",
        "plotExample(X_Image_test[i])"
      ],
      "metadata": {
        "id": "K5cL5orVXlRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(new_model, \"/tmp/dense/\")\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/tmp/dense/\")\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('image_dense.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "gk__Y-ATZmU2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}