{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Unzip folder"
      ],
      "metadata": {
        "id": "mHsZWDDs4LVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'images.zip' -d images/"
      ],
      "metadata": {
        "id": "sFL5X-V14QJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqtNfrSXrqOW",
        "outputId": "ab0d31ca-2ecf-499e-ebb4-4537dd12547e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "lyyzBAoy4iO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "t9YnATN_4kpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Data and Create list of Input and Outputs"
      ],
      "metadata": {
        "id": "xiI7gCzz5iQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear las listas archivos de audio y su etiqueta correspondiente\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def getExamples(datafolder):\n",
        "  X_Image = []\n",
        "  Y_Classification = []\n",
        "\n",
        "  # Clasificaciones de clases\n",
        "  image_classes = [os.path.basename(x) for x in glob.glob(datafolder + '*')]\n",
        "\n",
        "  for i, image_class in enumerate(image_classes):\n",
        "    for file in glob.glob(os.path.join(datafolder, image_class) + '/*.jpg'):\n",
        "      X_Image.append(file)\n",
        "      if image_class == image_classes[0]:\n",
        "        Y_Classification.append(np.array(-1)) #\n",
        "      else:\n",
        "        Y_Classification.append(np.array(1))\n",
        "  return np.asarray(X_Image), np.asarray(Y_Classification)"
      ],
      "metadata": {
        "id": "eYBuzKh05qUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datafolder= '/content/images/'\n",
        "X_Image, Y_Class = getExamples(datafolder)\n",
        "print(len(X_Image), len(Y_Class))"
      ],
      "metadata": {
        "id": "qnprQTow6MdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_Image[0])\n",
        "print(Y_Class[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnKKo01YsK1S",
        "outputId": "6cd75f2d-55c8-4922-c3c3-550c8ea2ddc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/images/happy/happy233.jpg\n",
            "-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Image, X_Image_test, Y_Class, Y_Class_test = train_test_split(X_Image, Y_Class, test_size=0.25)\n",
        "print(len(X_Image))\n",
        "print(len(Y_Class))"
      ],
      "metadata": {
        "id": "EPqjmcg76nek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert file paths to tensors"
      ],
      "metadata": {
        "id": "cHWYPny8heVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadExample(example):\n",
        "  # Cargar la imagen\n",
        "  img = tf.io.read_file(example)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.rgb_to_grayscale(img);\n",
        "  img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "  #img = img/255.0\n",
        "  img = tf.reshape(img, [-1]);\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "q8TBb4rBhjcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = loadExample(X_Image[2])\n",
        "print(X_Image[0])"
      ],
      "metadata": {
        "id": "GD_xG5BQtss2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementar el generador de Datos\n",
        "\n",
        "class MySequence(tf.keras.utils.Sequence):\n",
        "\n",
        "  def __init__(self, x_image, y_class, batch_size):\n",
        "    self.x_image = x_image\n",
        "    self.y_class = y_class\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_image)//self.batch_size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    batch_y = self.y_class[idx * self.batch_size : (idx+1)*self.batch_size]\n",
        "    batch_x = np.zeros((self.batch_size, s.shape[0]))\n",
        "    for i in range(0, self.batch_size):\n",
        "      batch_x[i] = loadExample(self.x_image[idx * self.batch_size + i])\n",
        "    return batch_x, batch_y"
      ],
      "metadata": {
        "id": "WroQouxJ6-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la forma de los datos de entrada y la salida esperada\n",
        "\n",
        "mS=MySequence(X_Image, Y_Class, 32)\n",
        "my_data=iter(mS)\n",
        "bx, by = next(my_data)\n",
        "print(bx.shape, by.shape)"
      ],
      "metadata": {
        "id": "jkq5db_q7bw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Lineal Model"
      ],
      "metadata": {
        "id": "9qtL_ZmSj4sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.Module):\n",
        "  #def __init__(self):\n",
        "  def __init__(self, name=None):\n",
        "    super().__init__(name=name)\n",
        "    initial_w = tf.zeros(shape=[307200])\n",
        "    initial_b =tf.zeros(shape=[1])\n",
        "    self.w = tf.Variable(initial_w)\n",
        "    self.b = tf.Variable(initial_b)\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[None,307200], dtype=tf.float32)])\n",
        "  def __call__(self, w):\n",
        "    return tf.reduce_sum(self.w*w, axis=[-1]) + self.b;"
      ],
      "metadata": {
        "id": "1GS4V1BBj6tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Watch Graph"
      ],
      "metadata": {
        "id": "cEUhfGpJkC5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "from datetime import datetime\n",
        "# Set up logging.\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = \"logs/func/%s\" % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "# Create a new model to get a fresh trace\n",
        "# Otherwise the summary will not see the graph.\n",
        "new_model = MyModel()\n",
        "\n",
        "# Bracket the function call with\n",
        "# tf.summary.trace_on() and tf.summary.trace_export().\n",
        "tf.summary.trace_on(graph=True)\n",
        "#tf.profiler.experimental.start(logdir)\n",
        "# Call only one tf.function when tracing.\n",
        "z = print(new_model( tf.random.uniform(shape=[1,307200], minval=-1.0, maxval=1.0)))\n",
        "with writer.as_default():\n",
        "  tf.summary.trace_export(\n",
        "      name=\"my_func_trace\",\n",
        "      step=0,\n",
        "      profiler_outdir=logdir)\n",
        "%tensorboard --logdir logs/func"
      ],
      "metadata": {
        "id": "rHFiR5mKkEYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = MyModel()"
      ],
      "metadata": {
        "id": "rRN5tzCgzZoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Loss  (Hinge Loss)\n",
        "$Loss = \\frac{1}{2}\\ \\|w\\|^2 +  C*\\sum_{i=1}^{m}max(0, 1 - y_i * pred)$"
      ],
      "metadata": {
        "id": "xDJg2ftwzu56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_val = 0.01\n",
        "def hinge(pred, y, model):\n",
        "  regularizationTerm  = tf.reduce_sum(tf.square(model.w)) *lambda_val/2\n",
        "  classificationTerm  = tf.reduce_mean(tf.maximum(0., tf.subtract(1., tf.multiply(pred, y))))\n",
        "  return tf.add(classificationTerm, regularizationTerm)"
      ],
      "metadata": {
        "id": "HvrOQryqzx8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "iA9fOXaU2lUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  my_data=iter(mS)\n",
        "  for x_batch, y_batch in my_data:\n",
        "    with tf.GradientTape() as tape:\n",
        "      batch_loss = hinge(new_model(x_batch), y_batch, new_model)\n",
        "\n",
        "    # Update parameters with respect to the gradient calculations\n",
        "    grads = tape.gradient(batch_loss, new_model.variables)\n",
        "    for g,v in zip(grads, new_model.variables):\n",
        "        v.assign_sub(0.1*g)\n",
        "  # Keep track of model loss per epoch\n",
        "  loss = hinge(new_model(x_batch), y_batch, new_model)\n",
        "  print(f\"Epoch {epoch} Loss  is {loss.numpy()}\",)"
      ],
      "metadata": {
        "id": "zxvkm2yX2mnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check Accuracy in Test Dataset"
      ],
      "metadata": {
        "id": "F9SnsTjEEu9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for x_image, y_class in zip(X_Image_test, Y_Class_test):\n",
        "  x_input = loadExample(x_image)\n",
        "  pred = new_model([x_input])\n",
        "  results.append(tf.cast(tf.equal(tf.sign(pred),y_class) , tf.float32))\n",
        "\n",
        "print(f\"Accuracy {tf.reduce_mean(results).numpy() * 100} %\")"
      ],
      "metadata": {
        "id": "CHR-AdX9QkgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotExample(example):\n",
        "  # Cargar la imagen\n",
        "  img = tf.io.read_file(example)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  plt.imshow(img)"
      ],
      "metadata": {
        "id": "1aPbwuTQfNNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=100\n",
        "print(Y_Class_test[i])\n",
        "print(X_Image_test[i])\n",
        "pred = new_model([loadExample(X_Image_test[i])])\n",
        "print(pred.numpy())\n",
        "plotExample(X_Image_test[i])"
      ],
      "metadata": {
        "id": "K5cL5orVXlRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(new_model, \"/tmp/svm/\")\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/tmp/svm\")\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('image_svm.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "dRA1tHqDe8aB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}