{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow"
      ],
      "metadata": {
        "id": "mPcvDe0wtCTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.12.0"
      ],
      "metadata": {
        "id": "D_FXaOictACa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unzip folder"
      ],
      "metadata": {
        "id": "mHsZWDDs4LVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'images.zip' -d images/"
      ],
      "metadata": {
        "id": "sFL5X-V14QJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "lyyzBAoy4iO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "t9YnATN_4kpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Data"
      ],
      "metadata": {
        "id": "xiI7gCzz5iQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear las listas archivos de audio y su etiqueta correspondiente\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def getExamples(datafolder):\n",
        "  X_Image = []\n",
        "  Y_Classification = []\n",
        "\n",
        "  # Clasificaciones de clases\n",
        "  image_classes = [os.path.basename(x) for x in glob.glob(datafolder + '*')]\n",
        "\n",
        "  for i, image_class in enumerate(image_classes):\n",
        "    for file in glob.glob(os.path.join(datafolder, image_class) + '/*.jpg'):\n",
        "      X_Image.append(file)\n",
        "      Y_Classification.append(np.array(to_categorical(i, num_classes=len(image_classes)),dtype=np.float32))\n",
        "  return np.asarray(X_Image), np.asarray(Y_Classification)"
      ],
      "metadata": {
        "id": "eYBuzKh05qUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datafolder= '/content/images/'\n",
        "X_Image, Y_Class = getExamples(datafolder)\n",
        "print(len(X_Image), len(Y_Class))"
      ],
      "metadata": {
        "id": "qnprQTow6MdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_Image[300])\n",
        "print(Y_Class[300])"
      ],
      "metadata": {
        "id": "tnKKo01YsK1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Image, X_Image_test, Y_Class, Y_Class_test = train_test_split(X_Image, Y_Class, test_size=0.25)\n",
        "print(len(X_Image))\n",
        "print(len(Y_Class))"
      ],
      "metadata": {
        "id": "EPqjmcg76nek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert file paths to tensors"
      ],
      "metadata": {
        "id": "cHWYPny8heVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadExample(example):\n",
        "  # Cargar la imagen\n",
        "  img = tf.io.read_file(example)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize(img, [48,64], preserve_aspect_ratio=True)\n",
        "  img = tf.image.rgb_to_grayscale(img);\n",
        "  img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "  #img = img/255.0\n",
        "  img = tf.reshape(img, [img.shape[0], img.shape[1], 1]);\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "q8TBb4rBhjcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = loadExample(X_Image[0])\n",
        "s.shape"
      ],
      "metadata": {
        "id": "GD_xG5BQtss2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementar el generador de Datos\n",
        "\n",
        "class MySequence(tf.keras.utils.Sequence):\n",
        "\n",
        "  def __init__(self, x_image, y_class, batch_size):\n",
        "    self.x_image = x_image\n",
        "    self.y_class = y_class\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_image)//self.batch_size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    batch_y = self.y_class[idx * self.batch_size : (idx+1)*self.batch_size]\n",
        "    batch_x = np.zeros((self.batch_size, s.shape[0], s.shape[1], s.shape[2]), dtype=np.float32)\n",
        "    for i in range(0, self.batch_size):\n",
        "      batch_x[i] = loadExample(self.x_image[idx * self.batch_size + i])\n",
        "    return batch_x, batch_y"
      ],
      "metadata": {
        "id": "WroQouxJ6-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la forma de los datos de entrada y la salida esperada\n",
        "\n",
        "mS=MySequence(X_Image, Y_Class, 32)\n",
        "my_data=iter(mS)\n",
        "bx, by = next(my_data)\n",
        "print(bx.shape, by.shape)"
      ],
      "metadata": {
        "id": "jkq5db_q7bw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Keras Libraries"
      ],
      "metadata": {
        "id": "9qtL_ZmSj4sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, Ad\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout, Flatten\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "1GS4V1BBj6tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Model"
      ],
      "metadata": {
        "id": "tQORzspGunVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_tensor = Input(shape=(48, 64,1))\n",
        "x = Conv2D(32, 3, activation='relu')(input_tensor)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(32, 3, activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_tensor = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=output_tensor)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n"
      ],
      "metadata": {
        "id": "SFfqnFXWloQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Watch Graph"
      ],
      "metadata": {
        "id": "cEUhfGpJkC5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "rHFiR5mKkEYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, to_file=\"model.png\", show_shapes=True)"
      ],
      "metadata": {
        "id": "eKL2zN1qzU0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "iA9fOXaU2lUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs = 1\n",
        "h = model.fit(MySequence(X_Image, Y_Class, batch_size),\n",
        "              shuffle=True,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=MySequence(X_Image_test, Y_Class_test, batch_size))"
      ],
      "metadata": {
        "id": "zxvkm2yX2mnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotExample(example):\n",
        "  # Cargar la imagen\n",
        "  img = tf.io.read_file(example)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  plt.imshow(img)"
      ],
      "metadata": {
        "id": "1aPbwuTQfNNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make Prediction"
      ],
      "metadata": {
        "id": "cFVJslYpS0PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=5\n",
        "print(Y_Class_test[i])\n",
        "print(X_Image_test[i])\n",
        "\n",
        "plotExample(X_Image_test[i])\n",
        "tensor = loadExample(X_Image_test[i])\n",
        "tensor = tf.reshape(tensor, shape=[1,48,64,1])\n",
        "\n",
        "model.predict(tensor)"
      ],
      "metadata": {
        "id": "K5cL5orVXlRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/modelAudioRecognition.h5')"
      ],
      "metadata": {
        "id": "SUQDSNIdRIk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "smodel=load_model('/content/modelAudioRecognition.h5')"
      ],
      "metadata": {
        "id": "zwGMBOTgniO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(smodel)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('audio_cnn.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "8bxQaLrYnkFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}